# =============================================================================
# VPS environment config — EXAMPLE
#
# Copy this folder and fill in your values:
#   cd environments
#   cp -r vps-example/ vps-prod/
#   vim vps-prod/config.yml
#
# Deploy (first time — Talos not yet on disk):
#   cd ansible
#   1. Boot VPS into rescue mode (provider dashboard)
#   2. ansible-playbook vps-deploy-rescue.yml -e env=../environments/vps-prod
#   3. Switch VPS boot mode back to normal (provider dashboard)
#   4. Reboot VPS (provider dashboard)
#   5. Wait ~60s for Talos maintenance mode
#   6. ansible-playbook vps-deploy.yml -e env=../environments/vps-prod
#
# Deploy (re-deploy — Talos already on disk, just re-bootstrap):
#   cd ansible
#   ansible-playbook vps-deploy.yml -e env=../environments/vps-prod
#
# Destroy:
#   ansible-playbook vps-destroy.yml -e env=../environments/vps-prod
# =============================================================================

# --- Platform ---
# Must be "proxmox" or "vps". Controls which playbook to use.
platform: vps

# --- Talos ---
talos_version: v1.12.4
# Schematic ID from factory.talos.dev (includes extensions: iscsi-tools, util-linux-tools)
talos_schematic_id: e187c9b90f773cd8c84e5a3265c5554ee787b2fe67b508d9f955e90e7ae8c96c
talos_install_disk: /dev/sda

# --- Cluster ---
cluster_name: fluodata
# No VIP on VPS — no shared L2 for gratuitous ARP.
# cluster_vip is intentionally NOT set. API endpoint uses first CP node IP.

# --- Network ---
# Public network — each node has a public IP assigned by the VPS provider.
# Gateway is the provider-assigned gateway for your IP block.
vm_gateway: REPLACE_WITH_GATEWAY
vm_subnet_mask: 32
vm_nameservers:
  - 213.186.33.99
  - 1.1.1.1

# --- Nodes ---
# All 3 nodes are combined controlplane + worker.
# Each needs: name, ip (public IP)
# For rescue mode install, also: rescue_ssh_host, rescue_ssh_user, rescue_ssh_pass
# rescue_ssh_pass is needed when rescue mode uses password auth (e.g., OVH)
controlplane_nodes:
  - name: node-0
    ip: REPLACE_WITH_VPS_0_PUBLIC_IP
    rescue_ssh_host: REPLACE_WITH_VPS_0_PUBLIC_IP
    rescue_ssh_pass: REPLACE_OR_REMOVE
  - name: node-1
    ip: REPLACE_WITH_VPS_1_PUBLIC_IP
    rescue_ssh_host: REPLACE_WITH_VPS_1_PUBLIC_IP
    rescue_ssh_pass: REPLACE_OR_REMOVE
  - name: node-2
    ip: REPLACE_WITH_VPS_2_PUBLIC_IP
    rescue_ssh_host: REPLACE_WITH_VPS_2_PUBLIC_IP
    rescue_ssh_pass: REPLACE_OR_REMOVE

# No dedicated workers — all nodes are combined CP+worker
worker_nodes: []

# --- Cilium ---
cilium_version: "1.17.3"
